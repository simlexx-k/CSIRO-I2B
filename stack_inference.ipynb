{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b2d3543",
   "metadata": {},
   "source": [
    "# CSIRO Biomass – Inference Notebook\n",
    "\n",
    "This notebook blends precomputed pillar submissions (SigLIP, DINO, MVP, Dinov2) into the final `submission.csv`.\n",
    "\n",
    "**Usage**\n",
    "1. Attach the dataset that contains the four pillar CSVs.\n",
    "2. Update the file paths in the next cell if your dataset uses different names.\n",
    "3. Run all cells – no training is performed here, so scoring should complete quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8680dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# === Configure pillar submission paths ===\n",
    "# Replace with the actual dataset paths you attached to this notebook.\n",
    "SIGLIP_PATH = Path('/kaggle/input/pillar-submissions/submission_siglip.csv')\n",
    "DINO_PATH = Path('/kaggle/input/pillar-submissions/submission3.csv')\n",
    "MVP_PATH = Path('/kaggle/input/pillar-submissions/submission2.csv')\n",
    "DINOV2_PATH = Path('/kaggle/input/pillar-submissions/submission_dinov2.csv')\n",
    "\n",
    "# Default SigLIP-heavy weights (SigLIP / DINO / MVP / Dinov2)\n",
    "WEIGHTS = np.array([0.60, 0.20, 0.10, 0.10], dtype=np.float64)\n",
    "\n",
    "# Optional clipping of target predictions\n",
    "CLIP_MIN = 0.0\n",
    "CLIP_MAX = None\n",
    "\n",
    "print('Configured weights (unnormalized):', WEIGHTS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf558f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUIRED_COLS = ('sample_id', 'target')\n",
    "\n",
    "def load_submission(path: Path) -> pd.DataFrame:\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f'Missing submission file: {path}')\n",
    "    df = pd.read_csv(path)\n",
    "    missing = [c for c in REQUIRED_COLS if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f'{path} missing column(s): {missing}')\n",
    "    return df[list(REQUIRED_COLS)].copy()\n",
    "\n",
    "weights = WEIGHTS.astype(np.float64)\n",
    "if np.any(weights < 0):\n",
    "    raise ValueError('Weights must be non-negative.')\n",
    "total = weights.sum()\n",
    "if total <= 0:\n",
    "    raise ValueError('Weights sum to zero; provide positive weights.')\n",
    "weights /= total\n",
    "print('Normalized weights:', weights.round(4))\n",
    "\n",
    "siglip_df = load_submission(SIGLIP_PATH)\n",
    "dino_df = load_submission(DINO_PATH)\n",
    "mvp_df = load_submission(MVP_PATH)\n",
    "dinov2_df = load_submission(DINOV2_PATH)\n",
    "\n",
    "id_column = siglip_df['sample_id']\n",
    "for name, pillar_df in (\n",
    "    ('DINO', dino_df),\n",
    "    ('MVP', mvp_df),\n",
    "    ('Dinov2', dinov2_df),\n",
    "):\n",
    "    if not pillar_df['sample_id'].equals(id_column):\n",
    "        raise ValueError(f'{name} submission sample_id ordering does not match SigLIP.')\n",
    "\n",
    "stacked = np.stack([\n",
    "    siglip_df['target'].to_numpy(dtype=np.float64),\n",
    "    dino_df['target'].to_numpy(dtype=np.float64),\n",
    "    mvp_df['target'].to_numpy(dtype=np.float64),\n",
    "    dinov2_df['target'].to_numpy(dtype=np.float64),\n",
    "], axis=0)\n",
    "\n",
    "blended = np.tensordot(weights, stacked, axes=(0, 0))\n",
    "if CLIP_MIN is not None or CLIP_MAX is not None:\n",
    "    blended = np.clip(blended, CLIP_MIN, CLIP_MAX)\n",
    "\n",
    "submission = pd.DataFrame({'sample_id': id_column, 'target': blended})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(f'Saved blended submission with {len(submission):,} rows to submission.csv')\n",
    "submission.head()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
