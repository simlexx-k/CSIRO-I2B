{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CSIRO - Image2Biomass with DINOv2 ViT\n",
        "Fine-tunes Meta's DINOv2 Vision Transformer (via `timm`) on the CSIRO Image2Biomass dataset to predict five pasture biomass measurements from aerial imagery."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Approach Overview\n",
        "We load the provided train/test CSVs, reshape labels into per-image targets, and split folds by image. A DINOv2 backbone feeds a lightweight regression head, optimizing Smooth L1 losses across all biomass components. After training, we ensemble fold checkpoints to generate predictions and write the final `submission.csv`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "!pip install -q timm==0.9.16 albumentations==1.4.14"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os",
        "import math",
        "import random",
        "import time",
        "from pathlib import Path",
        "from dataclasses import dataclass, asdict",
        "",
        "import numpy as np",
        "import pandas as pd",
        "from PIL import Image",
        "",
        "import torch",
        "from torch import nn",
        "from torch.utils.data import Dataset, DataLoader",
        "from torch.optim import AdamW",
        "from torch.optim.lr_scheduler import OneCycleLR",
        "from sklearn.model_selection import GroupKFold",
        "",
        "import timm",
        "from timm.data import create_transform",
        "",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "@dataclass",
        "class CFG:",
        "    data_dir: Path = Path('/kaggle/input/csiro-biomass')",
        "    output_dir: Path = Path('.')",
        "    seed: int = 2024",
        "    img_size: int = 392",
        "    batch_size: int = 16",
        "    num_workers: int = 4",
        "    epochs: int = 5",
        "    lr: float = 2e-4",
        "    min_lr: float = 1e-6",
        "    weight_decay: float = 1e-4",
        "    backbone: str = 'vit_base_patch14_dinov2'",
        "    hidden_dim: int = 512",
        "    drop_rate: float = 0.1",
        "    n_folds: int = 5",
        "    train_folds: tuple = (0,)",
        "    target_names: tuple = ('Dry_Clover_g','Dry_Dead_g','Dry_Green_g','Dry_Total_g','GDM_g')",
        "    num_targets: int = 5",
        "    use_amp: bool = True",
        "    grad_accum_steps: int = 1",
        "",
        "cfg = CFG()",
        "",
        "possible_dirs = [",
        "    Path('/kaggle/input/csiro-biomass'),",
        "    Path('/kaggle/input/CSIRO-I2B'),",
        "    Path('csiro-biomass'),",
        "]",
        "for p in possible_dirs:",
        "    if p.exists():",
        "        cfg.data_dir = p",
        "        break",
        "print(f\"Using data from: {cfg.data_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def seed_everything(seed: int = 42):",
        "    random.seed(seed)",
        "    np.random.seed(seed)",
        "    torch.manual_seed(seed)",
        "    torch.cuda.manual_seed_all(seed)",
        "    torch.backends.cudnn.deterministic = True",
        "    torch.backends.cudnn.benchmark = False",
        "",
        "seed_everything(cfg.seed)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(cfg.data_dir / 'train.csv')",
        "test_df = pd.read_csv(cfg.data_dir / 'test.csv')",
        "",
        "train_targets = train_df.pivot_table(",
        "    index='image_path',",
        "    columns='target_name',",
        "    values='target'",
        ").reset_index().copy()",
        "train_targets.columns.name = None",
        "train_targets = train_targets[['image_path', *cfg.target_names]]",
        "train_targets = train_targets.fillna(0.0)",
        "",
        "train_targets['fold'] = -1",
        "kf = GroupKFold(n_splits=cfg.n_folds)",
        "for fold, (_, val_idx) in enumerate(kf.split(train_targets, groups=train_targets['image_path'])):",
        "    train_targets.loc[val_idx, 'fold'] = fold",
        "",
        "print(train_targets.head())",
        "print(train_targets['fold'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "class BiomassDataset(Dataset):",
        "    def __init__(self, df: pd.DataFrame, mode: str, transform=None):",
        "        self.df = df.reset_index(drop=True)",
        "        self.mode = mode",
        "        self.transform = transform",
        "",
        "    def __len__(self):",
        "        return len(self.df)",
        "",
        "    def __getitem__(self, idx):",
        "        row = self.df.iloc[idx]",
        "        image_path = cfg.data_dir / row['image_path']",
        "        image = Image.open(image_path).convert('RGB')",
        "        if self.transform:",
        "            image = self.transform(image)",
        "        else:",
        "            image = transforms.ToTensor()(image)",
        "        sample = {",
        "            'pixel_values': image,",
        "            'image_path': row['image_path']",
        "        }",
        "        if self.mode != 'test':",
        "            target = torch.tensor(row[cfg.target_names].values, dtype=torch.float32)",
        "            sample['targets'] = target",
        "        return sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from torchvision import transforms",
        "",
        "def get_transforms(is_train=True):",
        "    if is_train:",
        "        return create_transform(",
        "            input_size=(3, cfg.img_size, cfg.img_size),",
        "            is_training=True,",
        "            auto_augment='rand-m9-mstd0.5-inc1',",
        "            interpolation='bicubic',",
        "            re_prob=0.25,",
        "            re_mode='pixel',",
        "            re_count=1,",
        "        )",
        "    else:",
        "        return create_transform(",
        "            input_size=(3, cfg.img_size, cfg.img_size),",
        "            is_training=False,",
        "            interpolation='bicubic',",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "class DinoRegressor(nn.Module):",
        "    def __init__(self, cfg):",
        "        super().__init__()",
        "        self.backbone = timm.create_model(",
        "            cfg.backbone,",
        "            pretrained=True,",
        "            num_classes=0,",
        "            global_pool='avg'",
        "        )",
        "        in_features = self.backbone.num_features",
        "        self.head = nn.Sequential(",
        "            nn.LayerNorm(in_features),",
        "            nn.Dropout(cfg.drop_rate),",
        "            nn.Linear(in_features, cfg.hidden_dim),",
        "            nn.GELU(),",
        "            nn.Dropout(cfg.drop_rate),",
        "            nn.Linear(cfg.hidden_dim, cfg.num_targets)",
        "        )",
        "",
        "    def forward(self, pixel_values):",
        "        feats = self.backbone(pixel_values)",
        "        return self.head(feats)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "class AverageMeter:",
        "    def __init__(self):",
        "        self.reset()",
        "    def reset(self):",
        "        self.val = 0",
        "        self.avg = 0",
        "        self.sum = 0",
        "        self.count = 0",
        "    def update(self, val, n=1):",
        "        self.val = val",
        "        self.sum += val * n",
        "        self.count += n",
        "        self.avg = self.sum / self.count if self.count != 0 else 0",
        "",
        "def get_dataloaders(train_df, valid_df):",
        "    train_dataset = BiomassDataset(train_df, mode='train', transform=get_transforms(True))",
        "    valid_dataset = BiomassDataset(valid_df, mode='valid', transform=get_transforms(False))",
        "",
        "    train_loader = DataLoader(",
        "        train_dataset,",
        "        batch_size=cfg.batch_size,",
        "        shuffle=True,",
        "        num_workers=cfg.num_workers,",
        "        pin_memory=True,",
        "        drop_last=True,",
        "    )",
        "    valid_loader = DataLoader(",
        "        valid_dataset,",
        "        batch_size=cfg.batch_size,",
        "        shuffle=False,",
        "        num_workers=cfg.num_workers,",
        "        pin_memory=True,",
        "        drop_last=False,",
        "    )",
        "    return train_loader, valid_loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def train_one_epoch(model, loader, criterion, optimizer, scheduler, scaler, device):",
        "    model.train()",
        "    loss_meter = AverageMeter()",
        "",
        "    for step, batch in enumerate(loader):",
        "        images = batch['pixel_values'].to(device, non_blocking=True)",
        "        targets = batch['targets'].to(device, non_blocking=True)",
        "        optimizer.zero_grad()",
        "        with torch.cuda.amp.autocast(enabled=cfg.use_amp):",
        "            preds = model(images)",
        "            loss = criterion(preds, targets)",
        "        scaler.scale(loss).backward()",
        "        scaler.step(optimizer)",
        "        scaler.update()",
        "        if scheduler is not None:",
        "            scheduler.step()",
        "        loss_meter.update(loss.item(), images.size(0))",
        "    return loss_meter.avg",
        "",
        "def validate_one_epoch(model, loader, criterion, device):",
        "    model.eval()",
        "    loss_meter = AverageMeter()",
        "    preds_list = []",
        "    with torch.no_grad():",
        "        for batch in loader:",
        "            images = batch['pixel_values'].to(device, non_blocking=True)",
        "            targets = batch['targets'].to(device, non_blocking=True)",
        "            with torch.cuda.amp.autocast(enabled=cfg.use_amp):",
        "                preds = model(images)",
        "                loss = criterion(preds, targets)",
        "            loss_meter.update(loss.item(), images.size(0))",
        "            preds_list.append(preds.detach().cpu())",
        "    predictions = torch.cat(preds_list).numpy()",
        "    return loss_meter.avg, predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'",
        "criterion = nn.SmoothL1Loss()",
        "oof_predictions = np.zeros((len(train_targets), cfg.num_targets), dtype=np.float32)",
        "test_images = pd.DataFrame({'image_path': test_df['image_path'].unique()})",
        "",
        "all_fold_models = []",
        "",
        "for fold in range(cfg.n_folds):",
        "    if fold not in cfg.train_folds:",
        "        continue",
        "    print(f\"",
        "===== Fold {fold} =====\")",
        "    train_split = train_targets[train_targets['fold'] != fold].reset_index(drop=True)",
        "    valid_split = train_targets[train_targets['fold'] == fold].reset_index(drop=True)",
        "    train_loader, valid_loader = get_dataloaders(train_split, valid_split)",
        "",
        "    model = DinoRegressor(cfg).to(DEVICE)",
        "    optimizer = AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)",
        "    steps_per_epoch = len(train_loader)",
        "    scheduler = OneCycleLR(",
        "        optimizer,",
        "        max_lr=cfg.lr,",
        "        epochs=cfg.epochs,",
        "        steps_per_epoch=steps_per_epoch,",
        "        pct_start=0.1,",
        "        div_factor=25,",
        "        final_div_factor=cfg.lr / cfg.min_lr,",
        "    )",
        "    scaler = torch.cuda.amp.GradScaler(enabled=cfg.use_amp)",
        "",
        "    best_loss = float('inf')",
        "    best_state = None",
        "",
        "    for epoch in range(cfg.epochs):",
        "        start = time.time()",
        "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, scheduler, scaler, DEVICE)",
        "        val_loss, val_preds = validate_one_epoch(model, valid_loader, criterion, DEVICE)",
        "        duration = time.time() - start",
        "        print(f\"Epoch {epoch+1}/{cfg.epochs} | train: {train_loss:.4f} | valid: {val_loss:.4f} | {duration:.1f}s\")",
        "        if val_loss < best_loss:",
        "            best_loss = val_loss",
        "            best_state = model.state_dict()",
        "    model.load_state_dict(best_state)",
        "    all_fold_models.append(best_state)",
        "",
        "    fold_idx = valid_split.index",
        "    oof_predictions[fold_idx] = val_preds",
        "",
        "np.save(cfg.output_dir / 'oof_predictions.npy', oof_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def infer(model_states, df):\n",
        "    models = []\n",
        "    for state in model_states:\n",
        "        model = DinoRegressor(cfg).to(DEVICE)\n",
        "        model.load_state_dict(state, strict=True)\n",
        "        model.eval()\n",
        "        models.append(model)\n",
        "    dataset = BiomassDataset(df, mode='test', transform=get_transforms(False))\n",
        "    loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=cfg.batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=cfg.num_workers,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "    image_preds = {}\n",
        "    for batch in loader:\n",
        "        images = batch['pixel_values'].to(DEVICE, non_blocking=True)\n",
        "        preds = torch.zeros((images.size(0), cfg.num_targets), device=DEVICE)\n",
        "        for model in models:\n",
        "            preds += model(images)\n",
        "        preds /= len(models)\n",
        "        preds = preds.detach().cpu().numpy()\n",
        "        for path, pred in zip(batch['image_path'], preds):\n",
        "            image_preds[path] = pred\n",
        "    return image_preds\n",
        "\n",
        "ensemble_preds = infer(all_fold_models, test_images)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "submission = test_df.copy()",
        "submission['target'] = submission.apply(",
        "    lambda row: ensemble_preds[row['image_path']][cfg.target_names.index(row['target_name'])],",
        "    axis=1",
        ")",
        "submission[['sample_id', 'target']].to_csv('submission.csv', index=False)",
        "submission.head()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}