{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 112509,
          "databundleVersionId": 14254895,
          "sourceType": "competition"
        }
      ],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "47843f56-629b-4bcb-a106-cea915c82666",
      "cell_type": "markdown",
      "source": [
        "# CSIRO - Image2Biomass with DINOv2 ViT\n",
        "Fine-tunes Meta's DINOv2 Vision Transformer (via `timm`) on the CSIRO Image2Biomass dataset to predict five pasture biomass measurements from aerial imagery.\n"
      ],
      "metadata": {}
    },
    {
      "id": "cfab2976-b2e0-4fd2-9bb5-834f1a34edfb",
      "cell_type": "markdown",
      "source": [
        "## Approach Overview\n",
        "We load the provided train/test CSVs, reshape labels into per-image targets, and split folds by image. A DINOv2 backbone feeds a lightweight regression head, optimizing Smooth L1 losses across all biomass components. After training, we ensemble fold checkpoints to generate predictions and write the final `submission.csv`.\n"
      ],
      "metadata": {}
    },
    {
      "id": "049d3534-08c3-457f-b694-c5252040696e",
      "cell_type": "code",
      "source": [
        "!pip install -q timm==0.9.16 albumentations==1.4.14 scikit-learn==1.3.2 scipy==1.11.4\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-29T08:38:12.528210Z",
          "iopub.execute_input": "2025-12-29T08:38:12.528573Z",
          "iopub.status.idle": "2025-12-29T08:38:15.975892Z",
          "shell.execute_reply.started": "2025-12-29T08:38:12.528522Z",
          "shell.execute_reply": "2025-12-29T08:38:15.975053Z"
        }
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "id": "dcfefec6-8315-4ac1-99f7-9b41d4c97a11",
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import random\n",
        "import time\n",
        "from pathlib import Path\n",
        "from dataclasses import dataclass, asdict\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch \n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "from sklearn.model_selection import GroupKFold\n",
        "import timm\n",
        "from timm.data import create_transform\n",
        "print(torch.__version__)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-29T08:41:10.607169Z",
          "iopub.execute_input": "2025-12-29T08:41:10.607413Z",
          "iopub.status.idle": "2025-12-29T08:41:15.940130Z",
          "shell.execute_reply.started": "2025-12-29T08:41:10.607396Z",
          "shell.execute_reply": "2025-12-29T08:41:15.939028Z"
        }
      },
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_47/2150595168.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdamW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOneCycleLR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGroupKFold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtimm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtimm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__check_build\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_IS_32BIT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_output\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_SetOutputMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m from .utils._tags import (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdeprecation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdiscovery\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mall_estimators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparse_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreadpool_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m from .validation import (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mthreadpoolctl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/stats/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    622\u001b[0m from ._warnings_errors import (ConstantInputWarning, NearConstantInputWarning,\n\u001b[1;32m    623\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[0;32m--> 624\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_stats_py\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_variation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvariation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/stats/_stats_py.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatial\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistance_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmilp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinearConstraint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/spatial/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_plotutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_procrustes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprocrustes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_geometric_slerp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgeometric_slerp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;31m# Deprecated namespaces, to be removed in v2.0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/spatial/_geometric_slerp.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0meuclidean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_hausdorff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrel_entr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_distance_pybind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/special/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    824\u001b[0m     chdtr, chdtrc, betainc, betaincc, stdtr)\n\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_basic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_basic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/special/_basic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_specfun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_comb\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_comb_int\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m from ._multiufuncs import (assoc_legendre_p_all,\n\u001b[0m\u001b[1;32m     23\u001b[0m                            legendre_p_all)\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_deprecated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/special/_multiufuncs.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m sph_legendre_p = MultiUFunc(\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0msph_legendre_p\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     r\"\"\"sph_legendre_p(n, m, theta, *, diff_n=0)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/special/_multiufuncs.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ufunc_or_ufuncs, doc, force_complex_output, **default_kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mufunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mufuncs_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mufunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mufunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                     raise ValueError(\"All ufuncs must have type `numpy.ufunc`.\"\n\u001b[0m\u001b[1;32m     42\u001b[0m                                      f\" Received {ufunc_or_ufuncs}\")\n\u001b[1;32m     43\u001b[0m                 \u001b[0mseen_input_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrozenset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"->\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: All ufuncs must have type `numpy.ufunc`. Received (<ufunc 'sph_legendre_p'>, <ufunc 'sph_legendre_p'>, <ufunc 'sph_legendre_p'>)"
          ],
          "ename": "ValueError",
          "evalue": "All ufuncs must have type `numpy.ufunc`. Received (<ufunc 'sph_legendre_p'>, <ufunc 'sph_legendre_p'>, <ufunc 'sph_legendre_p'>)",
          "output_type": "error"
        }
      ],
      "execution_count": 8
    },
    {
      "id": "a3004792-5215-49dc-ac44-652f9ee69612",
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class CFG:\n",
        "    data_dir: Path = Path('/kaggle/input/csiro-biomass')\n",
        "    output_dir: Path = Path('.')\n",
        "    seed: int = 2024\n",
        "    img_size: int = 518\n",
        "    batch_size: int = 16\n",
        "    num_workers: int = 4\n",
        "    epochs: int = 5\n",
        "    lr: float = 2e-4\n",
        "    min_lr: float = 1e-6\n",
        "    weight_decay: float = 1e-4\n",
        "    backbone: str = 'vit_base_patch14_dinov2'\n",
        "    hidden_dim: int = 512\n",
        "    drop_rate: float = 0.1\n",
        "    n_folds: int = 5\n",
        "    train_folds: tuple = (0,)\n",
        "    target_names: tuple = ('Dry_Clover_g','Dry_Dead_g','Dry_Green_g','Dry_Total_g','GDM_g')\n",
        "    num_targets: int = 5\n",
        "    use_amp: bool = True\n",
        "    grad_accum_steps: int = 1\n",
        "\n",
        "cfg = CFG()\n",
        "\n",
        "possible_dirs = [\n",
        "    Path('/kaggle/input/csiro-biomass'),\n",
        "    Path('/kaggle/input/CSIRO-I2B'),\n",
        "    Path('csiro-biomass'),\n",
        "]\n",
        "for p in possible_dirs:\n",
        "    if p.exists():\n",
        "        cfg.data_dir = p\n",
        "        break\n",
        "print(f\"Using data from: {cfg.data_dir}\")"
      ],
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "35bed8be-3163-4de2-9904-e5fac6474726",
      "cell_type": "code",
      "source": [
        "def seed_everything(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_everything(cfg.seed)\n"
      ],
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "8feec992-ada7-41be-9bbe-3d73c5badc9e",
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(cfg.data_dir / 'train.csv')\n",
        "test_df = pd.read_csv(cfg.data_dir / 'test.csv')\n",
        "\n",
        "train_targets = train_df.pivot_table(\n",
        "    index='image_path',\n",
        "    columns='target_name',\n",
        "    values='target'\n",
        ").reset_index().copy()\n",
        "cols = ['image_path', *list(cfg.target_names)]\n",
        "train_targets.columns = cols\n",
        "train_targets[list(cfg.target_names)] = train_targets[list(cfg.target_names)].fillna(0.0).astype(float)\n",
        "\n",
        "train_targets['fold'] = -1\n",
        "kf = GroupKFold(n_splits=cfg.n_folds)\n",
        "for fold, (_, val_idx) in enumerate(kf.split(train_targets, groups=train_targets['image_path'])):\n",
        "    train_targets.loc[val_idx, 'fold'] = fold\n",
        "\n",
        "print(train_targets.head())\n",
        "print(train_targets['fold'].value_counts())"
      ],
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "d6e6f63d-642e-4f0b-a67f-ee749afdd127",
      "cell_type": "code",
      "source": [
        "class BiomassDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, mode: str, transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.mode = mode\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        image_path = cfg.data_dir / row['image_path']\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        else:\n",
        "            image = transforms.ToTensor()(image)\n",
        "        sample = {\n",
        "            'pixel_values': image,\n",
        "            'image_path': row['image_path']\n",
        "        }\n",
        "        if self.mode != 'test':\n",
        "            targets = row[list(cfg.target_names)].astype(float).values\n",
        "            target = torch.tensor(targets, dtype=torch.float32)\n",
        "            sample['targets'] = target\n",
        "        return sample"
      ],
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "74a00df1-9518-4d6a-8fe5-f6ea06b57717",
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "def get_transforms(is_train=True):\n",
        "    if is_train:\n",
        "        return create_transform(\n",
        "            input_size=(3, cfg.img_size, cfg.img_size),\n",
        "            is_training=True,\n",
        "            auto_augment='rand-m9-mstd0.5-inc1',\n",
        "            interpolation='bicubic',\n",
        "            re_prob=0.25,\n",
        "            re_mode='pixel',\n",
        "            re_count=1,\n",
        "        )\n",
        "    else:\n",
        "        return create_transform(\n",
        "            input_size=(3, cfg.img_size, cfg.img_size),\n",
        "            is_training=False,\n",
        "            interpolation='bicubic',\n",
        "        )\n"
      ],
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "31ef70d1-a437-4c99-9583-af739617372b",
      "cell_type": "code",
      "source": [
        "class DinoRegressor(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.backbone = timm.create_model(\n",
        "            cfg.backbone,\n",
        "            pretrained=True,\n",
        "            num_classes=0,\n",
        "            global_pool=''\n",
        "        )\n",
        "        in_features = self.backbone.num_features\n",
        "        self.head = nn.Sequential(\n",
        "            nn.LayerNorm(in_features),\n",
        "            nn.Dropout(cfg.drop_rate),\n",
        "            nn.Linear(in_features, cfg.hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(cfg.drop_rate),\n",
        "            nn.Linear(cfg.hidden_dim, cfg.num_targets)\n",
        "        )\n",
        "\n",
        "    def forward(self, pixel_values):\n",
        "        feats = self.backbone(pixel_values)\n",
        "        return self.head(feats)"
      ],
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "0da93c08-389f-4aa8-8e06-e44c10859cf7",
      "cell_type": "code",
      "source": [
        "class AverageMeter:\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count if self.count != 0 else 0\n",
        "\n",
        "def get_dataloaders(train_df, valid_df):\n",
        "    train_dataset = BiomassDataset(train_df, mode='train', transform=get_transforms(True))\n",
        "    valid_dataset = BiomassDataset(valid_df, mode='valid', transform=get_transforms(False))\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=cfg.batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=cfg.num_workers,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    valid_loader = DataLoader(\n",
        "        valid_dataset,\n",
        "        batch_size=cfg.batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=cfg.num_workers,\n",
        "        pin_memory=True,\n",
        "        drop_last=False,\n",
        "    )\n",
        "    return train_loader, valid_loader\n"
      ],
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "5917ce57-d4ba-473b-9119-16fabc177d25",
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, loader, criterion, optimizer, scheduler, scaler, device):\n",
        "    model.train()\n",
        "    loss_meter = AverageMeter()\n",
        "\n",
        "    for step, batch in enumerate(loader):\n",
        "        images = batch['pixel_values'].to(device, non_blocking=True)\n",
        "        targets = batch['targets'].to(device, non_blocking=True)\n",
        "        optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast(enabled=cfg.use_amp):\n",
        "            preds = model(images)\n",
        "            loss = criterion(preds, targets)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "        loss_meter.update(loss.item(), images.size(0))\n",
        "    return loss_meter.avg\n",
        "\n",
        "\n",
        "def validate_one_epoch(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    loss_meter = AverageMeter()\n",
        "    preds_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            images = batch['pixel_values'].to(device, non_blocking=True)\n",
        "            targets = batch['targets'].to(device, non_blocking=True)\n",
        "            with torch.cuda.amp.autocast(enabled=cfg.use_amp):\n",
        "                preds = model(images)\n",
        "                loss = criterion(preds, targets)\n",
        "            loss_meter.update(loss.item(), images.size(0))\n",
        "            preds_list.append(preds.detach().cpu())\n",
        "    predictions = torch.cat(preds_list).numpy()\n",
        "    return loss_meter.avg, predictions\n"
      ],
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "bf6dcc10-66bc-4978-a251-bbb5e432c1d0",
      "cell_type": "code",
      "source": [
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "criterion = nn.SmoothL1Loss()\n",
        "oof_predictions = np.zeros((len(train_targets), cfg.num_targets), dtype=np.float32)\n",
        "test_images = pd.DataFrame({'image_path': test_df['image_path'].unique()})\n",
        "\n",
        "all_fold_models = []\n",
        "\n",
        "for fold in range(cfg.n_folds):\n",
        "    if fold not in cfg.train_folds:\n",
        "        continue\n",
        "    print(f\"===== Fold {fold} =====\")\n",
        "    train_split = train_targets[train_targets['fold'] != fold].reset_index(drop=True)\n",
        "    valid_split = train_targets[train_targets['fold'] == fold].reset_index(drop=True)\n",
        "    train_loader, valid_loader = get_dataloaders(train_split, valid_split)\n",
        "\n",
        "    model = DinoRegressor(cfg).to(DEVICE)\n",
        "    optimizer = AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
        "    steps_per_epoch = len(train_loader)\n",
        "    scheduler = OneCycleLR(\n",
        "        optimizer,\n",
        "        max_lr=cfg.lr,\n",
        "        epochs=cfg.epochs,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        pct_start=0.1,\n",
        "        div_factor=25,\n",
        "        final_div_factor=cfg.lr / cfg.min_lr,\n",
        "    )\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=cfg.use_amp)\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    best_state = None\n",
        "\n",
        "    for epoch in range(cfg.epochs):\n",
        "        start = time.time()\n",
        "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, scheduler, scaler, DEVICE)\n",
        "        val_loss, val_preds = validate_one_epoch(model, valid_loader, criterion, DEVICE)\n",
        "        duration = time.time() - start\n",
        "        print(f\"Epoch {epoch+1}/{cfg.epochs} | train: {train_loss:.4f} | valid: {val_loss:.4f} | {duration:.1f}s\")\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            best_state = model.state_dict()\n",
        "    model.load_state_dict(best_state)\n",
        "    all_fold_models.append(best_state)\n",
        "\n",
        "    fold_idx = valid_split.index\n",
        "    oof_predictions[fold_idx] = val_preds\n",
        "\n",
        "np.save(cfg.output_dir / 'oof_predictions.npy', oof_predictions)\n"
      ],
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "d2240157-689c-413d-b285-dd9243de22cc",
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def infer(model_states, df):\n",
        "    models = []\n",
        "    for state in model_states:\n",
        "        model = DinoRegressor(cfg).to(DEVICE)\n",
        "        model.load_state_dict(state, strict=True)\n",
        "        model.eval()\n",
        "        models.append(model)\n",
        "    dataset = BiomassDataset(df, mode='test', transform=get_transforms(False))\n",
        "    loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=cfg.batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=cfg.num_workers,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "    image_preds = {}\n",
        "    for batch in loader:\n",
        "        images = batch['pixel_values'].to(DEVICE, non_blocking=True)\n",
        "        preds = torch.zeros((images.size(0), cfg.num_targets), device=DEVICE)\n",
        "        for model in models:\n",
        "            preds += model(images)\n",
        "        preds /= len(models)\n",
        "        preds = preds.detach().cpu().numpy()\n",
        "        for path, pred in zip(batch['image_path'], preds):\n",
        "            image_preds[path] = pred\n",
        "    return image_preds\n",
        "\n",
        "ensemble_preds = infer(all_fold_models, test_images)\n"
      ],
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "f48aea55-555b-4395-bfd0-5646f0e94a80",
      "cell_type": "code",
      "source": [
        "submission = test_df.copy()\n",
        "submission['target'] = submission.apply(\n",
        "    lambda row: ensemble_preds[row['image_path']][cfg.target_names.index(row['target_name'])],\n",
        "    axis=1\n",
        ")\n",
        "submission[['sample_id', 'target']].to_csv('submission.csv', index=False)\n",
        "submission.head()\n"
      ],
      "metadata": {},
      "outputs": [],
      "execution_count": null
    }
  ]
}