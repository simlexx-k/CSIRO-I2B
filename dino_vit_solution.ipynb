{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":112509,"databundleVersionId":14254895,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"47843f56-629b-4bcb-a106-cea915c82666","cell_type":"markdown","source":"# CSIRO - Image2Biomass with DINOv2 ViT\nFine-tunes Meta's DINOv2 Vision Transformer (via `timm`) on the CSIRO Image2Biomass dataset to predict five pasture biomass measurements from aerial imagery.","metadata":{}},{"id":"cfab2976-b2e0-4fd2-9bb5-834f1a34edfb","cell_type":"markdown","source":"## Approach Overview\nWe load the provided train/test CSVs, reshape labels into per-image targets, and split folds by image. A DINOv2 backbone feeds a lightweight regression head, optimizing Smooth L1 losses across all biomass components. After training, we ensemble fold checkpoints to generate predictions and write the final `submission.csv`.","metadata":{}},{"id":"049d3534-08c3-457f-b694-c5252040696e","cell_type":"code","source":"!pip install -q timm==1.0.22 albumentations==2.0.8 scikit-learn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T08:38:12.528210Z","iopub.execute_input":"2025-12-29T08:38:12.528573Z","iopub.status.idle":"2025-12-29T08:38:15.975892Z","shell.execute_reply.started":"2025-12-29T08:38:12.528522Z","shell.execute_reply":"2025-12-29T08:38:15.975053Z"}},"outputs":[],"execution_count":2},{"id":"dcfefec6-8315-4ac1-99f7-9b41d4c97a11","cell_type":"code","source":"import os\nimport math\nimport random\nimport time\nfrom pathlib import Path\nfrom dataclasses import dataclass, asdict\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport torch \nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import AdamW\nfrom torch.optim.lr_scheduler import OneCycleLR\nfrom sklearn.model_selection import GroupKFold\nimport timm\nfrom timm.data import create_transform\nprint(torch.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T08:41:10.607169Z","iopub.execute_input":"2025-12-29T08:41:10.607413Z","iopub.status.idle":"2025-12-29T08:41:15.940130Z","shell.execute_reply.started":"2025-12-29T08:41:10.607396Z","shell.execute_reply":"2025-12-29T08:41:15.939028Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/2150595168.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdamW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOneCycleLR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGroupKFold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtimm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtimm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__check_build\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_IS_32BIT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_output\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_SetOutputMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m from .utils._tags import (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdeprecation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdiscovery\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mall_estimators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparse_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreadpool_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m from .validation import (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mthreadpoolctl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/stats/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    622\u001b[0m from ._warnings_errors import (ConstantInputWarning, NearConstantInputWarning,\n\u001b[1;32m    623\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[0;32m--> 624\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_stats_py\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_variation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvariation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/stats/_stats_py.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatial\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistance_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmilp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinearConstraint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/spatial/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_plotutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_procrustes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprocrustes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_geometric_slerp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgeometric_slerp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;31m# Deprecated namespaces, to be removed in v2.0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/spatial/_geometric_slerp.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0meuclidean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_hausdorff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrel_entr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_distance_pybind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/special/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    824\u001b[0m     chdtr, chdtrc, betainc, betaincc, stdtr)\n\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_basic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_basic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/special/_basic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_specfun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_comb\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_comb_int\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m from ._multiufuncs import (assoc_legendre_p_all,\n\u001b[0m\u001b[1;32m     23\u001b[0m                            legendre_p_all)\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_deprecated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/special/_multiufuncs.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m sph_legendre_p = MultiUFunc(\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0msph_legendre_p\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     r\"\"\"sph_legendre_p(n, m, theta, *, diff_n=0)\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/special/_multiufuncs.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ufunc_or_ufuncs, doc, force_complex_output, **default_kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mufunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mufuncs_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mufunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mufunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                     raise ValueError(\"All ufuncs must have type `numpy.ufunc`.\"\n\u001b[0m\u001b[1;32m     42\u001b[0m                                      f\" Received {ufunc_or_ufuncs}\")\n\u001b[1;32m     43\u001b[0m                 \u001b[0mseen_input_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrozenset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"->\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: All ufuncs must have type `numpy.ufunc`. Received (<ufunc 'sph_legendre_p'>, <ufunc 'sph_legendre_p'>, <ufunc 'sph_legendre_p'>)"],"ename":"ValueError","evalue":"All ufuncs must have type `numpy.ufunc`. Received (<ufunc 'sph_legendre_p'>, <ufunc 'sph_legendre_p'>, <ufunc 'sph_legendre_p'>)","output_type":"error"}],"execution_count":8},{"id":"a3004792-5215-49dc-ac44-652f9ee69612","cell_type":"code","source":"@dataclassclass CFG:    data_dir: Path = Path('/kaggle/input/csiro-biomass')    output_dir: Path = Path('.')    seed: int = 2024    img_size: int = 392    batch_size: int = 16    num_workers: int = 4    epochs: int = 5    lr: float = 2e-4    min_lr: float = 1e-6    weight_decay: float = 1e-4    backbone: str = 'vit_base_patch14_dinov2'    hidden_dim: int = 512    drop_rate: float = 0.1    n_folds: int = 5    train_folds: tuple = (0,)    target_names: tuple = ('Dry_Clover_g','Dry_Dead_g','Dry_Green_g','Dry_Total_g','GDM_g')    num_targets: int = 5    use_amp: bool = True    grad_accum_steps: int = 1cfg = CFG()possible_dirs = [    Path('/kaggle/input/csiro-biomass'),    Path('/kaggle/input/CSIRO-I2B'),    Path('csiro-biomass'),]for p in possible_dirs:    if p.exists():        cfg.data_dir = p        breakprint(f\"Using data from: {cfg.data_dir}\")","metadata":{},"outputs":[],"execution_count":null},{"id":"35bed8be-3163-4de2-9904-e5fac6474726","cell_type":"code","source":"def seed_everything(seed: int = 42):    random.seed(seed)    np.random.seed(seed)    torch.manual_seed(seed)    torch.cuda.manual_seed_all(seed)    torch.backends.cudnn.deterministic = True    torch.backends.cudnn.benchmark = Falseseed_everything(cfg.seed)","metadata":{},"outputs":[],"execution_count":null},{"id":"8feec992-ada7-41be-9bbe-3d73c5badc9e","cell_type":"code","source":"train_df = pd.read_csv(cfg.data_dir / 'train.csv')test_df = pd.read_csv(cfg.data_dir / 'test.csv')train_targets = train_df.pivot_table(    index='image_path',    columns='target_name',    values='target').reset_index().copy()train_targets.columns.name = Nonetrain_targets = train_targets[['image_path', *cfg.target_names]]train_targets = train_targets.fillna(0.0)train_targets['fold'] = -1kf = GroupKFold(n_splits=cfg.n_folds)for fold, (_, val_idx) in enumerate(kf.split(train_targets, groups=train_targets['image_path'])):    train_targets.loc[val_idx, 'fold'] = foldprint(train_targets.head())print(train_targets['fold'].value_counts())","metadata":{},"outputs":[],"execution_count":null},{"id":"d6e6f63d-642e-4f0b-a67f-ee749afdd127","cell_type":"code","source":"class BiomassDataset(Dataset):    def __init__(self, df: pd.DataFrame, mode: str, transform=None):        self.df = df.reset_index(drop=True)        self.mode = mode        self.transform = transform    def __len__(self):        return len(self.df)    def __getitem__(self, idx):        row = self.df.iloc[idx]        image_path = cfg.data_dir / row['image_path']        image = Image.open(image_path).convert('RGB')        if self.transform:            image = self.transform(image)        else:            image = transforms.ToTensor()(image)        sample = {            'pixel_values': image,            'image_path': row['image_path']        }        if self.mode != 'test':            target = torch.tensor(row[cfg.target_names].values, dtype=torch.float32)            sample['targets'] = target        return sample","metadata":{},"outputs":[],"execution_count":null},{"id":"74a00df1-9518-4d6a-8fe5-f6ea06b57717","cell_type":"code","source":"from torchvision import transformsdef get_transforms(is_train=True):    if is_train:        return create_transform(            input_size=(3, cfg.img_size, cfg.img_size),            is_training=True,            auto_augment='rand-m9-mstd0.5-inc1',            interpolation='bicubic',            re_prob=0.25,            re_mode='pixel',            re_count=1,        )    else:        return create_transform(            input_size=(3, cfg.img_size, cfg.img_size),            is_training=False,            interpolation='bicubic',        )","metadata":{},"outputs":[],"execution_count":null},{"id":"31ef70d1-a437-4c99-9583-af739617372b","cell_type":"code","source":"class DinoRegressor(nn.Module):    def __init__(self, cfg):        super().__init__()        self.backbone = timm.create_model(            cfg.backbone,            pretrained=True,            num_classes=0,            global_pool='avg'        )        in_features = self.backbone.num_features        self.head = nn.Sequential(            nn.LayerNorm(in_features),            nn.Dropout(cfg.drop_rate),            nn.Linear(in_features, cfg.hidden_dim),            nn.GELU(),            nn.Dropout(cfg.drop_rate),            nn.Linear(cfg.hidden_dim, cfg.num_targets)        )    def forward(self, pixel_values):        feats = self.backbone(pixel_values)        return self.head(feats)","metadata":{},"outputs":[],"execution_count":null},{"id":"0da93c08-389f-4aa8-8e06-e44c10859cf7","cell_type":"code","source":"class AverageMeter:    def __init__(self):        self.reset()    def reset(self):        self.val = 0        self.avg = 0        self.sum = 0        self.count = 0    def update(self, val, n=1):        self.val = val        self.sum += val * n        self.count += n        self.avg = self.sum / self.count if self.count != 0 else 0def get_dataloaders(train_df, valid_df):    train_dataset = BiomassDataset(train_df, mode='train', transform=get_transforms(True))    valid_dataset = BiomassDataset(valid_df, mode='valid', transform=get_transforms(False))    train_loader = DataLoader(        train_dataset,        batch_size=cfg.batch_size,        shuffle=True,        num_workers=cfg.num_workers,        pin_memory=True,        drop_last=True,    )    valid_loader = DataLoader(        valid_dataset,        batch_size=cfg.batch_size,        shuffle=False,        num_workers=cfg.num_workers,        pin_memory=True,        drop_last=False,    )    return train_loader, valid_loader","metadata":{},"outputs":[],"execution_count":null},{"id":"5917ce57-d4ba-473b-9119-16fabc177d25","cell_type":"code","source":"def train_one_epoch(model, loader, criterion, optimizer, scheduler, scaler, device):    model.train()    loss_meter = AverageMeter()    for step, batch in enumerate(loader):        images = batch['pixel_values'].to(device, non_blocking=True)        targets = batch['targets'].to(device, non_blocking=True)        optimizer.zero_grad()        with torch.cuda.amp.autocast(enabled=cfg.use_amp):            preds = model(images)            loss = criterion(preds, targets)        scaler.scale(loss).backward()        scaler.step(optimizer)        scaler.update()        if scheduler is not None:            scheduler.step()        loss_meter.update(loss.item(), images.size(0))    return loss_meter.avgdef validate_one_epoch(model, loader, criterion, device):    model.eval()    loss_meter = AverageMeter()    preds_list = []    with torch.no_grad():        for batch in loader:            images = batch['pixel_values'].to(device, non_blocking=True)            targets = batch['targets'].to(device, non_blocking=True)            with torch.cuda.amp.autocast(enabled=cfg.use_amp):                preds = model(images)                loss = criterion(preds, targets)            loss_meter.update(loss.item(), images.size(0))            preds_list.append(preds.detach().cpu())    predictions = torch.cat(preds_list).numpy()    return loss_meter.avg, predictions","metadata":{},"outputs":[],"execution_count":null},{"id":"bf6dcc10-66bc-4978-a251-bbb5e432c1d0","cell_type":"code","source":"DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'criterion = nn.SmoothL1Loss()oof_predictions = np.zeros((len(train_targets), cfg.num_targets), dtype=np.float32)test_images = pd.DataFrame({'image_path': test_df['image_path'].unique()})all_fold_models = []for fold in range(cfg.n_folds):    if fold not in cfg.train_folds:        continue    print(f\"===== Fold {fold} =====\")    train_split = train_targets[train_targets['fold'] != fold].reset_index(drop=True)    valid_split = train_targets[train_targets['fold'] == fold].reset_index(drop=True)    train_loader, valid_loader = get_dataloaders(train_split, valid_split)    model = DinoRegressor(cfg).to(DEVICE)    optimizer = AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)    steps_per_epoch = len(train_loader)    scheduler = OneCycleLR(        optimizer,        max_lr=cfg.lr,        epochs=cfg.epochs,        steps_per_epoch=steps_per_epoch,        pct_start=0.1,        div_factor=25,        final_div_factor=cfg.lr / cfg.min_lr,    )    scaler = torch.cuda.amp.GradScaler(enabled=cfg.use_amp)    best_loss = float('inf')    best_state = None    for epoch in range(cfg.epochs):        start = time.time()        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, scheduler, scaler, DEVICE)        val_loss, val_preds = validate_one_epoch(model, valid_loader, criterion, DEVICE)        duration = time.time() - start        print(f\"Epoch {epoch+1}/{cfg.epochs} | train: {train_loss:.4f} | valid: {val_loss:.4f} | {duration:.1f}s\")        if val_loss < best_loss:            best_loss = val_loss            best_state = model.state_dict()    model.load_state_dict(best_state)    all_fold_models.append(best_state)    fold_idx = valid_split.index    oof_predictions[fold_idx] = val_predsnp.save(cfg.output_dir / 'oof_predictions.npy', oof_predictions)","metadata":{},"outputs":[],"execution_count":null},{"id":"d2240157-689c-413d-b285-dd9243de22cc","cell_type":"code","source":"@torch.no_grad()\ndef infer(model_states, df):\n    models = []\n    for state in model_states:\n        model = DinoRegressor(cfg).to(DEVICE)\n        model.load_state_dict(state, strict=True)\n        model.eval()\n        models.append(model)\n    dataset = BiomassDataset(df, mode='test', transform=get_transforms(False))\n    loader = DataLoader(\n        dataset,\n        batch_size=cfg.batch_size,\n        shuffle=False,\n        num_workers=cfg.num_workers,\n        pin_memory=True,\n    )\n    image_preds = {}\n    for batch in loader:\n        images = batch['pixel_values'].to(DEVICE, non_blocking=True)\n        preds = torch.zeros((images.size(0), cfg.num_targets), device=DEVICE)\n        for model in models:\n            preds += model(images)\n        preds /= len(models)\n        preds = preds.detach().cpu().numpy()\n        for path, pred in zip(batch['image_path'], preds):\n            image_preds[path] = pred\n    return image_preds\n\nensemble_preds = infer(all_fold_models, test_images)\n","metadata":{},"outputs":[],"execution_count":null},{"id":"f48aea55-555b-4395-bfd0-5646f0e94a80","cell_type":"code","source":"submission = test_df.copy()submission['target'] = submission.apply(    lambda row: ensemble_preds[row['image_path']][cfg.target_names.index(row['target_name'])],    axis=1)submission[['sample_id', 'target']].to_csv('submission.csv', index=False)submission.head()","metadata":{},"outputs":[],"execution_count":null}]}